{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed010cc-126c-4fd1-b25e-03542e83970e",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "This notebook shows how text is converted to vectors representing the original text. It follows the notebook here: https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/01_main-chapter-code/dataloader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214d4556-77a7-42c9-8a25-12c2ced355fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tiktoken\n",
    "import torch\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef4191-c0d3-4134-8e26-1796d539f910",
   "metadata": {},
   "source": [
    "## Tokenizing text\n",
    "\n",
    "In this section, we tokenize text, which means breaking text into smaller units, such as individual words and punctuation characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a0759-1585-4c68-9bd0-b137d01e3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw text\n",
    "if not os.path.exists(\"the-verdict.txt\"):\n",
    "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "           \"the-verdict.txt\")\n",
    "    file_path = \"the-verdict.txt\"\n",
    "    urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23fc95-b1f7-448f-8176-6e3f7f81db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea49520-bf2e-437b-ac0c-876031d9183f",
   "metadata": {},
   "source": [
    "- The goal is to tokenize and embed this text for an LLM\n",
    "- Let's develop a simple tokenizer based on some simple sample text that we can then later apply to the text above\n",
    "- The following regular expression will split on whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f8682-19ec-40ab-a19f-75fded9f86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a086dfff-db1e-403d-8ee1-4b93e9563c87",
   "metadata": {},
   "source": [
    "We don't only want to split on whitespaces but also commas and periods, so let's modify the regular expression to do that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f51a7d-1b6a-4799-b1e3-ed2d7bfb2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(r'([,.]|\\s)', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b386ab9-28bf-468f-ba7b-0e2c88f4f906",
   "metadata": {},
   "source": [
    "This creates empty strings, let's remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84a705a-eb41-4270-80c1-d698ca4f0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip whitespace from each item and then filter out any empty strings.\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a911c-fa24-480d-9644-0d0bee92c0d3",
   "metadata": {},
   "source": [
    "This looks pretty good, but let's also handle other types of punctuation, such as periods, question marks, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b585ba-b389-49af-8e93-28df8b1e7809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
